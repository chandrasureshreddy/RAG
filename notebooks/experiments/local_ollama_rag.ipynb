{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d5cab6-515e-4dd6-95ae-6393f0c4435c",
   "metadata": {},
   "source": [
    "## Ingesting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e8b999-83ba-484a-9b94-f56c201d2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.10.5 which is incompatible.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.2 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.2 which is incompatible.\n",
      "streamlit 1.30.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.3 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --q unstructured langchain langchain-community\n",
    "%pip install --q \"unstructured[all-docs]\" ipywidgets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0e2f74-7c4b-4665-8d87-bc00656f31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sures\\AppData\\Local\\Temp\\ipykernel_11804\\3632673901.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from IPython.display import display as Markdown\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104c0b18-1c06-41a1-a2ca-f9ee23f4f952",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_path:\n\u001b[0;32m      5\u001b[0m   loader \u001b[38;5;241m=\u001b[39m UnstructuredPDFLoader(file_path\u001b[38;5;241m=\u001b[39mlocal_path)\n\u001b[1;32m----> 6\u001b[0m   data \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload a PDF file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:31\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\langchain_community\\document_loaders\\unstructured.py:107\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_elements()\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_elements(elements)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:72\u001b[0m, in \u001b[0;36mUnstructuredPDFLoader._get_elements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munstructured_kwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\unstructured\\partition\\pdf.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m PILImage\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentLayout\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayoutelement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayoutElement\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_chunking_strategy\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\unstructured_inference\\inference\\layout.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayoutelement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayoutElement, LayoutElements\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munstructuredmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     UnstructuredElementExtractionModel,\n\u001b[0;32m     20\u001b[0m     UnstructuredObjectDetectionModel,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_bbox\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\unstructured_inference\\models\\base.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Tuple, Type\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetectron2onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MODEL_TYPES \u001b[38;5;28;01mas\u001b[39;00m DETECTRON2_ONNX_MODEL_TYPES,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetectron2onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredDetectronONNXModel\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munstructuredmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredModel\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\unstructured_inference\\models\\detectron2onnx.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HUGGINGFACE_HUB_CACHE\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pybind_state \u001b[38;5;28;01mas\u001b[39;00m C\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantType, quantize_dynamic\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Source\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\onnxruntime\\quantization\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalibrate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     CalibraterBase,\n\u001b[0;32m      3\u001b[0m     CalibrationDataReader,\n\u001b[0;32m      4\u001b[0m     CalibrationMethod,\n\u001b[0;32m      5\u001b[0m     MinMaxCalibrater,\n\u001b[0;32m      6\u001b[0m     create_calibrator,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqdq_quantizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QDQQuantizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquant_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantFormat, QuantType, write_calibration_table  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\onnxruntime\\quantization\\calibrate.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Sequence, Tuple, Union\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelProto, TensorProto, helper, numpy_helper\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Jupitor\\Lib\\site-packages\\onnx\\__init__.py:77\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IO, Literal, Union\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx_cpp2py_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ONNX_ML\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal_data_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     79\u001b[0m     load_external_data_for_model,\n\u001b[0;32m     80\u001b[0m     write_external_data_tensors,\n\u001b[0;32m     81\u001b[0m     convert_model_to_external_data,\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx_pb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     84\u001b[0m     AttributeProto,\n\u001b[0;32m     85\u001b[0m     EXPERIMENTAL,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m     Version,\n\u001b[0;32m    112\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "local_path = \"C:/Users/sures/Downloads/ollama_pdf_rag-main/ollama_pdf_rag-main/data/pdfs/sample/WEF_The_Global_Cooperation_Barometer_2024.pdf\"\n",
    "\n",
    "# Local PDF file uploads\n",
    "if local_path:\n",
    "  loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "  data = loader.load()\n",
    "else:\n",
    "  print(\"Upload a PDF file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38119195-9c91-4e58-aa46-8a74244032af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Preview first page\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Markdown(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Preview first page\n",
    "Markdown(data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faacc1-be29-4d52-a46e-94f5b5b8e728",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d5435cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED    \n",
      "minicpm-v:latest           1862d7d5fee5    5.5 GB    11 days ago    \n",
      "llava:latest               8dd30f6b0cb1    4.7 GB    2 weeks ago    \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    2 weeks ago    \n",
      "llama3.2:latest            a80c4f17acd5    2.0 GB    4 weeks ago    \n",
      "gemma2:latest              ff02c3702f32    5.4 GB    4 weeks ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dcf2cfe-a7aa-4ecf-85e3-f77b9e850514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Pull nomic-embed-text model from Ollama if you don't have it\n",
    "# !ollama pull nomic-embed-text\n",
    "# # List models again to confirm it's available\n",
    "# !ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "014e862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First clean up any existing ChromaDB installations\n",
    "%pip uninstall -y chromadb\n",
    "%pip uninstall -y protobuf\n",
    "\n",
    "# 2. Install specific versions known to work together\n",
    "%pip install -q protobuf==3.20.3\n",
    "%pip install -q chromadb==0.4.22  # Using a stable older version\n",
    "%pip install -q langchain-ollama\n",
    "\n",
    "# 3. Set the environment variable\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83a39856-0cc0-4ebe-8024-9db32455a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bad040e2-3abe-4e23-abb9-951b223b9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4ed9d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tonykipkemboi/YouTube/Coding Projects/ollama_pdf_rag/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/tonykipkemboi/YouTube/Coding Projects/ollama_pdf_rag/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/tonykipkemboi/YouTube/Coding Projects/ollama_pdf_rag/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/tonykipkemboi/YouTube/Coding Projects/ollama_pdf_rag/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/tonykipkemboi/YouTube/Coding Projects/ollama_pdf_rag/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1. First clean up any existing ChromaDB installations\n",
    "%pip uninstall -y chromadb\n",
    "%pip uninstall -y protobuf\n",
    "\n",
    "# 2. Install specific versions known to work together\n",
    "%pip install -q protobuf==3.20.3\n",
    "%pip install -q chromadb==0.4.22  # Using a stable older version\n",
    "%pip install -q langchain-ollama\n",
    "\n",
    "# 3. Set the environment variable\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "# 4. Now reimport with the new versions\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# 5. Try creating the vector database\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eadf50-2f3d-4420-8858-94e9c1682ffa",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ec338c4-f282-462f-b0a0-c1899538eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3f6c039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED    \n",
      "minicpm-v:latest           1862d7d5fee5    5.5 GB    11 days ago    \n",
      "llava:latest               8dd30f6b0cb1    4.7 GB    2 weeks ago    \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    2 weeks ago    \n",
      "llama3.2:latest            a80c4f17acd5    2.0 GB    4 weeks ago    \n",
      "gemma2:latest              ff02c3702f32    5.4 GB    4 weeks ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1d6ceeb-6883-4688-b923-e771c2b2cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM from Ollama\n",
    "local_model = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c436d5cd-5dd0-448c-b5c0-6eddab879c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71e423dc-f632-46f8-9bec-d74cb268ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb1f308f-8472-4506-9517-d79b61d408f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06c25c1d-d205-409e-90a2-179d0bd7c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 5 pillars of global cooperation, as analyzed by the Global Cooperation Barometer, are:\\n\\n1. **Trade and Capital**: Promote global development and resilience through the presence of global economic flows that promote likely opportunities for these outcomes.\\n2. **Innovation and Technology**: Accelerate innovation and beneficial technological progress through the global sharing of underlying knowledge that contributes to these outcomes by fostering collaboration across global talent.\\n3. **Climate and Natural Capital**: Focus on addressing climate change and promoting sustainable development through cooperation and collective action.\\n4. **Health and Wellness**: Promote global health and well-being through cooperative efforts in areas such as disease prevention, health security, and access to healthcare.\\n5. **Peace and Security**: Foster international peace and security through cooperation and conflict resolution mechanisms that promote stability and predictability.\\n\\nThese 5 pillars were chosen because of their impact on global development and their explicit dependence on cooperative efforts among nations and economies.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are the 5 pillars of global cooperation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfe79f21-48aa-4820-aa9f-79f3d1a0a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all collections in the db\n",
    "vector_db.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
